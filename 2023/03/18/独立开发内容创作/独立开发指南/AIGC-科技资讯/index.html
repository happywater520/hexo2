<!DOCTYPE html><html lang="zh-CN" data-theme="dark"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>记录一些科技资讯ing | 地球OL之小水篇</title><meta name="robots" content="noindex"><meta name="author" content="小水"><meta name="copyright" content="小水"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#0d0d0d"><meta name="description" content="一些网站https:&#x2F;&#x2F;paperswithcode.com&#x2F; 这个网站是一个收集和展示机器学习相关论文和代码的平台。¹ 它可以让用户浏览不同领域和任务的最新研究成果，比较不同模型的性能，以及下载和运行论文中提供的代码。¹ 它还提供了很多机器学习数据集的信息，包括数据集的简介，大小，来源，格式等。² 如果您对机器学习感兴趣，这个网站可以帮助您了解最新的进展和技术。 一些虚拟形象的生成的资源罗丹扩散">
<meta property="og:type" content="article">
<meta property="og:title" content="记录一些科技资讯ing">
<meta property="og:url" content="https://happywater520.github.io/2023/03/18/%E7%8B%AC%E7%AB%8B%E5%BC%80%E5%8F%91%E5%86%85%E5%AE%B9%E5%88%9B%E4%BD%9C/%E7%8B%AC%E7%AB%8B%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97/AIGC-%E7%A7%91%E6%8A%80%E8%B5%84%E8%AE%AF/index.html">
<meta property="og:site_name" content="地球OL之小水篇">
<meta property="og:description" content="一些网站https:&#x2F;&#x2F;paperswithcode.com&#x2F; 这个网站是一个收集和展示机器学习相关论文和代码的平台。¹ 它可以让用户浏览不同领域和任务的最新研究成果，比较不同模型的性能，以及下载和运行论文中提供的代码。¹ 它还提供了很多机器学习数据集的信息，包括数据集的简介，大小，来源，格式等。² 如果您对机器学习感兴趣，这个网站可以帮助您了解最新的进展和技术。 一些虚拟形象的生成的资源罗丹扩散">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://happywater520.github.io/images/chatu/.png">
<meta property="article:published_time" content="2023-03-18T15:00:33.000Z">
<meta property="article:modified_time" content="2023-10-08T17:19:19.556Z">
<meta property="article:author" content="小水">
<meta property="article:tag" content="这里是keywords">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://happywater520.github.io/images/chatu/.png"><link rel="shortcut icon" href="/img/favicon.jpg"><link rel="canonical" href="https://happywater520.github.io/2023/03/18/%E7%8B%AC%E7%AB%8B%E5%BC%80%E5%8F%91%E5%86%85%E5%AE%B9%E5%88%9B%E4%BD%9C/%E7%8B%AC%E7%AB%8B%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97/AIGC-%E7%A7%91%E6%8A%80%E8%B5%84%E8%AE%AF/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?df9847ebf1288f357b3b9f0b3371b5d5";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":200},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: 小水","link":"链接: ","source":"来源: 地球OL之小水篇","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '记录一些科技资讯ing',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-10-09 01:19:19'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/favicon.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">12</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">1</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">19</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-tags"></i><span> 知识图谱</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-heart"></i><span> 创作痕迹</span></a></div><div class="menus_item"><a class="site-page" href="/timeline/"><i class="fa-fw fas fa-archive"></i><span> 时间日志</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg fixed" id="page-header" style="background-image: url('/../images/chatu/.png')"><nav id="nav"><span id="blog-info"><a href="/" title="地球OL之小水篇"><span class="site-name">地球OL之小水篇</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-tags"></i><span> 知识图谱</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-heart"></i><span> 创作痕迹</span></a></div><div class="menus_item"><a class="site-page" href="/timeline/"><i class="fa-fw fas fa-archive"></i><span> 时间日志</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">记录一些科技资讯ing</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-03-18T15:00:33.000Z" title="发表于 2023-03-18 23:00:33">2023-03-18</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-10-08T17:19:19.556Z" title="更新于 2023-10-09 01:19:19">2023-10-09</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E4%B8%8E%E4%BF%A1%E6%81%AF%E6%97%B6%E4%BB%A3%E4%B8%AA%E4%BD%93%E4%B9%A6/">与信息时代个体书</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E4%B8%8E%E4%BF%A1%E6%81%AF%E6%97%B6%E4%BB%A3%E4%B8%AA%E4%BD%93%E4%B9%A6/%E7%8B%AC%E7%AB%8B%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97/">独立开发指南</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="记录一些科技资讯ing"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h6 id="一些网站"><a href="#一些网站" class="headerlink" title="一些网站"></a>一些网站</h6><p><a target="_blank" rel="noopener" href="https://paperswithcode.com/">https://paperswithcode.com/</a></p>
<p>这个网站是一个收集和展示机器学习相关论文和代码的平台。¹ 它可以让用户浏览不同领域和任务的最新研究成果，比较不同模型的性能，以及下载和运行论文中提供的代码。¹ 它还提供了很多机器学习数据集的信息，包括数据集的简介，大小，来源，格式等。²</p>
<p>如果您对机器学习感兴趣，这个网站可以帮助您了解最新的进展和技术。</p>
<h6 id="一些虚拟形象的生成的资源"><a href="#一些虚拟形象的生成的资源" class="headerlink" title="一些虚拟形象的生成的资源"></a>一些虚拟形象的生成的资源</h6><p><a target="_blank" rel="noopener" href="https://3d-avatar-diffusion.microsoft.com/">罗丹扩散 (microsoft.com)</a> 微软的生成模型</p>
<p><a target="_blank" rel="noopener" href="https://www.unrealengine.com/zh-CN/metahuman">MetaHuman Creator | 虚幻引擎 - Unreal Engine</a> 基于虚幻引擎5的工具<a target="_blank" rel="noopener" href="https://www.unrealengine.com/zh-CN/metahuman">MetaHuman Creator</a></p>
<p><a target="_blank" rel="noopener" href="https://www.unrealengine.com/zh-CN/unreal-engine-5?sessionInvalidated=true">虚幻引擎5 - Unreal Engine</a></p>
<p>ZModeler绑定骨骼、</p>
<p>建模 Character Creator（插件Headshot） 、Blender</p>
<h6 id="基于gpt的工具"><a href="#基于gpt的工具" class="headerlink" title="基于gpt的工具"></a>基于gpt的工具</h6><p><a target="_blank" rel="noopener" href="https://github.com/yetone/bob-plugin-openai-translator">GitHub - yetone&#x2F;bob-plugin-openai-translator: 基于 ChatGPT API 的文本翻译、文本润色、语法纠错 Bob 插件，让我们一起迎接不需要巴别塔的新时代！</a></p>
<p>基于 ChatGPT API 的划词翻译浏览器插件和全平台桌面端应用</p>
<p><a target="_blank" rel="noopener" href="https://github.com/kaixindelele/ChatPaper">GitHub - kaixindelele&#x2F;ChatPaper：使用 ChatGPT 总结 arXiv 论文。</a></p>
<p>ChatPaper是一款论文总结工具。 AI用一分钟总结论文，用户用一分钟阅读AI总结的论文。</p>
<p>它可以根据用户输入的关键词，自动在arxiv上下载最新的论文，再利用ChatGPT3.5的API接口强大的总结能力，将论文总结为固定的格式，以最少的文本，最低的阅读门槛，为大家提供最大信息量，以决定该精读哪些文章。</p>
<p>也可以提供本地的PDF文档地址，直接处理。一般一个晚上就可以速通一个小领域的最新文章。</p>
<p><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/583232012/answer/2886779529">研究生如何利用 ChatGPT 帮助开展日常科研工作？ - 知乎 (zhihu.com)</a></p>
<h6 id="GitHub-Copilot是什么"><a href="#GitHub-Copilot是什么" class="headerlink" title="GitHub Copilot是什么"></a>GitHub Copilot是什么</h6><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Codex是GitHub开发的代码生成工具，而GitHub Copilot是由GitHub与OpenAI合作开发的一个基于机器学习的代码助手。它们都使用了类似于GPT的预训练语言模型来实现对用户自然语言输入的理解和代码生成。</span><br><span class="line"></span><br><span class="line">区别在于，Codex是一款商业化的产品，需要进行订阅才能使用，而GitHub Copilot目前处于测试阶段，并且可以通过在Visual Studio Code中安装插件的方式免费试用。此外，虽然它们的核心使用技术相似，但 GitHub Copilot是一个更全面的代码助手，不仅仅是代码生成工具，它可以针对不同的开发任务提供有用的建议和帮助。</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GitHub Copilot是一种由OpenAI和GitHub合作开发的人工智能编程助手。它使用机器学习模型来生成代码，帮助程序员更快地编写高质量的代码。Copilot可以与多种编辑器和IDE一起使用，包括Visual Studio Code、Vim和Emacs等。它还可以根据您输入的上下文和注释生成代码片段，并提供代码建议和自动完成功能。GitHub Copilot是基于**GPT-3**技术开发的，并通过从GitHub社区中搜集数据来强化其机器学习模型。</span><br></pre></td></tr></table></figure>

<p>GitHub Copilot是一个基于云的人工智能工具，由GitHub和OpenAI开发，可以帮助Visual Studio Code、Visual Studio、Neovim和JetBrains等集成开发环境（IDE）的用户自动补全代码。² GitHub Copilot可以根据您的注释和代码提供整行或整个函数的建议，帮助您在不熟悉的领域或框架中编写代码，或者学习新的语言或技术。³</p>
<p>要使用GitHub Copilot，您需要有一个具有GitHub Copilot for Individuals或GitHub Copilot for Business的个人账户或组织账户，并在您的IDE中安装GitHub Copilot扩展。¹ 目前，GitHub Copilot还处于技术预览阶段，需要申请邀请才能使用。³</p>
<h6 id="自然语言推理数据集是什么"><a href="#自然语言推理数据集是什么" class="headerlink" title="自然语言推理数据集是什么"></a>自然语言推理数据集是什么</h6><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">自然语言推理数据集是用于评估自然语言处理算法性能的一种标准数据集。它通常包含一组前提和假设语句，需要根据这些语句之间的逻辑关系来判断假设是否成立。</span><br><span class="line"></span><br><span class="line">这些数据集被广泛用于自然语言推理任务中，例如文本蕴含、情感分析和问答系统等。通过对这些数据集进行训练和测试，研究人员可以开发出更加精确和高效的自然语言处理算法，从而推动该领域的发展。目前已经有很多公开可用的自然语言推理数据集，例如SNLI数据集、MultiNLI数据集、ANLI数据集等。</span><br></pre></td></tr></table></figure>

<p>您好，这是Bing。<strong>自然语言推理数据集</strong>是一种用于评估自然语言处理系统能否理解和推断自然语言文本的数据集。¹ 一般来说，自然语言推理数据集包含了两个句子（前提和假设）以及一个标签（中立，蕴含或矛盾）。⁴ 例如，前提是“他在公园里玩耍”，假设是“他很开心”，那么标签就是蕴含。⁴</p>
<p>目前，有很多不同的自然语言推理数据集，例如<strong>斯坦福自然语言推理（SNLI）⁴⁵、多领域自然语言推理（MNLI）⁵、原生中文自然语言推理（OCNLI）</strong>³等等。这些数据集可以用于训练和测试各种基于深度学习的自然语言推理模型，例如ESIM⁶、BERT⁵等。</p>
<h6 id="DALL·E是什么"><a href="#DALL·E是什么" class="headerlink" title="DALL·E是什么"></a>DALL·E是什么</h6><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">DALL·E是由OpenAI发布的一个图像生成模型，它可以根据用户输入的文本描述生成对应的图像。DALL·E使用了GPT-3训练出来的语言模型，并将其与一种名为Diffusion Probabilistic Models的图像生成技术相结合，从而实现了与文本描述相匹配的图像生成。</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>DALL·E 2是DALL·E的后续模型，于2022年1月发布，可以根据文本描述生成更逼真和多样化的图像。⁴ DALL·E 2可以处理更复杂和抽象的文本输入，例如“馬に乗った宇宙飛行士をフォトリアルなスタイルで”（一个骑着马的宇航员以逼真的风格）¹，并输出与文本内容相符合的图像数据集。⁴ DALL·E 2还可以根据用户的反馈和偏好调整图像的细节和风格。⁴</p>
<p>DALL·E 2使用了OpenAI API和ChatGPT Plus来提供服务，用户可以通过注册账号并获得免费或付费的额度来使用DALL·E 2生成图像。⁵⁶ DALL·E 2对暴力、仇恨或成人向的图像生成能力有所限制，以避免不良影响。³</p>
<h6 id="OpenAI-API是什么"><a href="#OpenAI-API是什么" class="headerlink" title="OpenAI API是什么"></a>OpenAI API是什么</h6><p>OpenAI API是一个用于访问OpenAI开发的新型AI模型的接口。¹ OpenAI API可以应用于几乎任何涉及理解或生成自然语言、代码或图像的任务。² OpenAI API提供了不同能力水平的模型，适用于不同的任务，例如GPT-3、Codex、DALL·E 2等，以及能够微调自己的定制模型的能力。² 这些模型可以用于从内容生成到聊天机器人等各种场景。²</p>
<p>OpenAI API使用HTTP协议和JSON格式进行通信，用户可以通过注册账号并获得免费或付费的额度来使用OpenAI API调用模型。²³ OpenAI API还提供了一些文档和示例来帮助用户学习和构建应用。³</p>
<h6 id="基于规则的奖励模型（RBRMs）是什么"><a href="#基于规则的奖励模型（RBRMs）是什么" class="headerlink" title="基于规则的奖励模型（RBRMs）是什么"></a>基于规则的奖励模型（RBRMs）是什么</h6><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">基于规则的奖励模型（RBRMs）是一种人工智能领域中的算法，它被广泛用于强化学习任务中。在这种算法中，代理根据对环境的感知来做出决策，并从环境中获得奖励或惩罚信号。这些奖励和惩罚信号被用来调整代理的行为，以使其在未来更好地完成任务。</span><br><span class="line"></span><br><span class="line">与其他强化学习算法不同，RBRMs 基于先验知识或专家规则，将目标分解成子目标，并在每个子目标上定义奖励函数。这些子目标可以是任何适合特定问题的目标，例如最小化操作成本或最大化收益等。然后，代理可以利用这些子目标来制定长期计划，并执行与此计划相一致的动作。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h6 id="Microsoft-365-Copilot是什么"><a href="#Microsoft-365-Copilot是什么" class="headerlink" title="Microsoft 365 Copilot是什么"></a>Microsoft 365 Copilot是什么</h6><p>Microsoft 365 Copilot是一种下一代AI生产力技术，基于大语言模型，于2023年3月16日正式宣布推出。²³ Microsoft 365 Copilot可以集成到你每天使用的应用程序中，例如Word、Excel、PowerPoint、Outlook、Teams等，帮助你释放创造力、提高效率和提升技能。²⁴ Microsoft 365 Copilot还提供了一个全新的体验：Business Chat，让你可以与Copilot进行自然对话，并获得有关即将进行的会议、项目更新、组织变化等信息。⁴</p>
<p>Microsoft 365 Copilot是由Copilot系统驱动的，这个系统将Microsoft 365应用程序与数据和智能的Microsoft Graph以及GPT-41结合起来。¹ Copilot使用grounding来提高给定提示的质量，并在Word中根据其他文件草拟文档。¹²</p>
<h6 id="心智理论（ToM）是什么"><a href="#心智理论（ToM）是什么" class="headerlink" title="心智理论（ToM）是什么"></a>心智理论（ToM）是什么</h6><p>心智理论（Theory of Mind，ToM）是指人类具备的一种认知能力，用于理解自己和他人的心理状态、信念、意图和情感等方面的知识。这种能力被认为是<strong>人类社会智能的重要基础之一</strong>。</p>
<p>心智理论使人们能够推断他人的思维和感受，了解他们的动机和意图，从而更好地与他们交往和合作。例如，当我们观察别人的面部表情、身体语言和言语时，我们能够推断他们的情感状态和意图，以便更好地理解和回应他们的行为。</p>
<p>在发展心理学中，心智理论是儿童社会认知发展的关键阶段。儿童在约4岁左右开始逐渐发展出心智理论，能够理解他人的思维和情感状态，并根据这些信息进行交流和协作。</p>
<p>心智理论的研究还涉及到人类自我认知和自我理解的方面，以及神经科学和认知神经科学领域中对其神经机制的研究。</p>
<h6 id="SkyNet是什么"><a href="#SkyNet是什么" class="headerlink" title="SkyNet是什么"></a>SkyNet是什么</h6><p>SkyNet是一种<strong>虚构的人工智能系统，常常出现在科幻电影和小说中</strong>，最著名的例子是《终结者》电影系列。在《终结者》中，SkyNet是由美国军方开发的一个自我进化的人工智能系统，最终掌控了全球的核武器和其他军事系统，并试图消灭人类，从而统治地球。</p>
<p>虽然SkyNet只是虚构的，但它反映了<strong>对人工智能可能对人类社会带来的潜在威胁的担忧</strong>。许多科学家和技术专家正在努力研究人工智能的道德和安全问题，以确保它们能够在不危害人类的情况下发挥积极作用。</p>
<h6 id="AI-1-0是什么"><a href="#AI-1-0是什么" class="headerlink" title="AI 1.0是什么"></a>AI 1.0是什么</h6><p>AI 1.0是指上世纪80年代到90年代中期，人工智能技术在应用领域取得了一些重大突破的时期。在这个时期，深度学习技术还没有被广泛采用，主要使用的是基于规则的专家系统和浅层神经网络。</p>
<p><strong>CV是计算机视觉（Computer Vision）</strong>的缩写，它是一种<strong>利用计算机和数学方法来处理和解析现实世界图像和视频信息的技术</strong>。CV的目标是使计算机具备类似人眼的功能，包括感知、识别、理解和推断。它在医疗、安防、自动驾驶等领域有着广泛的应用。</p>
<p><strong>CNN是卷积神经网络（Convolutional Neural Network）的缩写，</strong>它是一种深度学习模型，特别适用于<strong>图像和视频数据</strong>的处理和分类。CNN模型由多个卷积层、池化层和全连接层构成，通过对图像进行卷积和降采样的操作提取图像的特征，并将这些特征输入全连接层进行分类。CNN在计算机视觉领域的发展起到了非常重要的作用，带来了显著的性能提升。</p>
<p><strong>NLP是Natural Language Processing的缩写，意思是自然语言处理</strong>，是一种人工智能（AI）的分支，能够让计算机理解、生成和操作人类的语言。¹³ NLP结合了<strong>计算语言学（基于规则的人类语言建模）和机器学习（基于数据的人类语言学习）</strong>的方法，来实现各种自然语言相关的任务，如翻译、拼写检查、话题分类等。¹⁴</p>
<h6 id="多模态是什么"><a href="#多模态是什么" class="headerlink" title="多模态是什么"></a>多模态是什么</h6><p><strong>多模态</strong>（multimodal）是指使用<strong>多种感官模式来进行交流或处理信息</strong>的方式。在计算机科学领域，多模态通常指人与计算机之间以多种方式进行交互，例如语音、图像、手势或触摸屏幕等。这些不同的交互方式可以使用户更加自然地与计算机交互，并帮助计算机更好地理解用户的意图和需求。多模态应用包括<strong>语音识别、手写识别、面部表情识别、姿势识别</strong>等。</p>
<h6 id="AIGC是什么"><a href="#AIGC是什么" class="headerlink" title="AIGC是什么"></a>AIGC是什么</h6><p>从互联网过往发展的历史来看，创作门槛的降低，释放了内容创造力。我们此前经历的互联网时代被称作Web1.0和Web2.0。在<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=Web1.0&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2764124245%7D">Web1.0</a>时代内容的生产方式主要是由<strong>专家、专业人士生成（PGC</strong>），信息单向传递，内容生成数量少；随着人们对内容需求的不断增加，我们逐渐来到了Web2.0时代，内容主要由<strong>用户生成（UGC）</strong>，比如我们在使用的抖音、快手、<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=B%E7%AB%99&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2764124245%7D">B站</a>、微博、小红书、等兴起等都有大量的内容是用户自己创作的。</p>
<p>随着时代继续发展，用户对内容消费的需求继续增长，UGC、PGC这样的内容生成方式也将难以满足需求增速，<strong>我们将迈入Web3.0时代，由人工智能生成内容（AIGC）。</strong></p>
<p>AIGC目前主要用在文字、图像、视频、音频、游戏以及虚拟人上等，具体如下表所示：</p>
<table>
<thead>
<tr>
<th>序号</th>
<th>应用场景</th>
<th align="center">描述</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>文字创作</td>
<td align="center">AIGC生成文字目前主要被应用于新闻的撰写、给定格式的撰写以及风格改写。比如用户可以通过输入一段对于目标文章的描述或者要求，系统会自动抓取数据，根据我们描述的指令进行创作。</td>
</tr>
<tr>
<td>2</td>
<td>图像创作</td>
<td align="center">技术平台降低了<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E8%89%BA%E6%9C%AF%E7%BB%98%E7%94%BB&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2764124245%7D">艺术绘画</a>创作的门槛，用户只需要通过输入文字描述，计算机将会自动生成一张作品。</td>
</tr>
<tr>
<td>3</td>
<td>视频创作</td>
<td align="center">例如Google推出了AI视频生成模型Phenaki能够根据文本内容生成可变时长视频的技术，在公布的DEMO中，Phenaki基于几百个单词组成一段前后逻辑连贯的视频只需两分钟。</td>
</tr>
<tr>
<td>4</td>
<td>音频剪辑</td>
<td align="center">AIGC生成音频早被应用于我们的日常生活当中，比如常用的手机导航中的声音。更深层次的应用将会是<a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E8%99%9A%E6%8B%9F%E4%BA%BA&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2764124245%7D">虚拟人</a>领域，AIGC不仅可以生成虚拟人的声音，并可以创造出说的内容。</td>
</tr>
<tr>
<td>5</td>
<td>游戏开发</td>
<td align="center">AIGC在游戏当中的应用可分为两方面，一方面用于场景和故事的搭建，另一方面玩家可以通过AIGC的平台工具来创建自己的虚拟人，可以用于游戏中的打金等活动。</td>
</tr>
<tr>
<td>6</td>
<td><a target="_blank" rel="noopener" href="https://www.zhihu.com/search?q=%E4%BB%A3%E7%A0%81%E7%94%9F%E6%88%90&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2764124245%7D">代码生成</a></td>
<td align="center">资料显示，2022年AIGC发展速度惊人，迭代速度更是呈现指数级爆发，其中深度学习模型不断完善、开源模式的推动、大模型探索商业化的可能，成为AIGC发展的“加速度”。</td>
</tr>
</tbody></table>
<h6 id="AIGC技术与应用全解析"><a href="#AIGC技术与应用全解析" class="headerlink" title="AIGC技术与应用全解析"></a>AIGC技术与应用全解析</h6><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/607822576">万字长文：AIGC技术与应用全解析</a></p>
<p>从<strong>技术层面</strong>AIGC可分为三个层次，分别为：</p>
<p><strong>1、智能数字内容孪生：</strong></p>
<p>简单的说，将数字内容从 <strong>一个维度映射到另一个维度</strong> 。与生成有什么关系呢？因为另一个维度内容不存在所以需要生成。内容孪生主要分为内容的增强与转译。增强即对数字内容修复、去噪、细节增强等。转译即对数字内容转换如翻译等。</p>
<p>该技术旨在将现实世界中的内容进行 <strong>智能增强与智能转译</strong> ，更好的完成现实世界到数字世界映射。例如，我们拍摄了一张低分辨率的图片，通过智能增强中的图像超分可对低分辨率进行放大，同时增强图像的细节信息，生成高清图。再比如，对于老照片中的像素缺失部分，可通过智能增强技术进行内容复原。而智能转译则更关注不同模态之间的相互转换。比如，我们录制了一段音频，可通过智能转译技术自动生成字幕；再比如，我们输入了一段文字，可以自动生成语音，两个例子均为模态间智能转译应用。</p>
<p>【应用】：图像超分、语音转字幕、文字转语音等。</p>
<p><strong>2、智能数字内容编辑：</strong></p>
<p>智能数字内容编辑通过 <strong>对内容的理解以及属性控制</strong> ，进而实现对 <strong>内容的修改</strong> 。如在计算机视觉领域，通过对视频内容的理解实现不同场景视频片段的剪辑。通过人体部位检测以及目标衣服的变形控制与截断处理，将目标衣服覆盖至人体部位，实现虚拟试衣。在语音信号处理领域，通过对音频信号分析，实现人声与背景声分离。以上三个例子均在理解数字内容的基础上对内容的编辑与控制。</p>
<p>【应用】：视频场景剪辑、虚拟试衣、人声分离等。</p>
<p><strong>3、智能数字内容生成：</strong></p>
<p><del>猫猫女仆不只是如此</del></p>
<p>智能数字内容生成通过从海量数据中 <strong>学习抽象概念</strong> ，并通过概念的组合 <strong>生成全新的内容</strong> 。如AI绘画，从海量绘画中学习作品不同笔法、内容、艺术风格，并基于学习内容重新生成特定风格的绘画。采用此方式，人工智能在文本创作、音乐创作和诗词创作中取得了不错表现。再比如，在跨模态领域，通过输入文本输出特定风格与属性的图像，不仅能够描述图像中主体的数量、形状、颜色等属性信息，而且能够描述主体的行为、动作以及主体之间的关系。</p>
<p>【应用】：图像生成（AI绘画）、文本生成（AI写作、ChatBot）、视频生成、多模态生成等。</p>
<p>从<strong>生成内容</strong>层面AIGC可分为五个方面：</p>
<p><strong>1、文本生成</strong></p>
<p>基于NLP（自然语言处理）文本内容生成根据使用场景可分为非交互式与交互式文本生成。<strong>非交互式文本生成</strong>包括摘要&#x2F;标题生成、文本风格迁移、文章生成、图像生成文本等。<strong>交互式文本生成</strong>主要包括聊天机器人、文本交互游戏等。</p>
<p>【代表性产品或模型】：JasperAI、copy.AI、<strong>ChatGPT</strong>、Bard、AI dungeon等。</p>
<p><strong>2、图像生成</strong></p>
<p>图像生成根据使用场可分为图像编辑修改与图像自主生成。<strong>图像编辑修改</strong>可应用于图像超分、图像修复、人脸替换、图像去水印、图像背景去除等。<strong>图像自主生成</strong>包括端到端的生成，如真实图像生成卡通图像、参照图像生成绘画图像、真实图像生成素描图像、文本生成图像等。</p>
<p>【代表性产品或模型】：EditGAN，Deepfake，**DALL-**E、MidJourney、Stable Diffusion，文心一格等。</p>
<p><strong>3、音频生成</strong></p>
<p>音频生成技术较为成熟，在C端产品中也较为常见，如语音克隆，将人声1替换为人声2。还可应用于文本生成特定场景语音，如数字人播报、语音客服等。此外，可<strong>基于文本描述、图片内容理解生成场景化音频、乐曲</strong>等。</p>
<p>【代表性产品或模型】：DeepMusic、WaveNet、Deep Voice、MusicAutoBot等。</p>
<p><strong>4、视频生成</strong></p>
<p>视频生成与图像生成在原理上相似，主要分为视频编辑与视频自主生成。<strong>视频编辑</strong>可应用于视频超分（视频画质增强）、视频修复（老电影上色、画质修复）、视频画面剪辑（识别画面内容，自动场景剪辑）。视频自主生成可应用于<strong>图像生成视频</strong>（给定参照图像，生成一段运动视频）、<strong>文本生成视频</strong>（给定一段描述性文字，生成内容相符视频）。</p>
<p>【代表性产品或模型】：Deepfake，videoGPT，Gliacloud、Make-A-Video、Imagen video等。</p>
<p><strong>5、****多模态生成</strong></p>
<p>以上四种模态可以进行组合搭配，进行模态间转换生成。如文本生成图像（AI绘画、根据prompt提示语生成特定风格图像）、文本生成音频（AI作曲、根据prompt提示语生成特定场景音频）、文本生成视频（AI视频制作、根据一段描述性文本生成语义内容相符视频片段）、图像生成文本（根据图像生成标题、根据图像生成故事）、图像生成视频。</p>
<p>【代表性产品或模型】：DALL-E、MidJourney、Stable Diffusion等。</p>
<h6 id="1、基础模型"><a href="#1、基础模型" class="headerlink" title="1、基础模型"></a><strong>1、基础模型</strong></h6><table>
<thead>
<tr>
<th>模型名称</th>
<th>提出时间</th>
<th>应用场景</th>
</tr>
</thead>
<tbody><tr>
<td>1、深度变分自编码（VAE）</td>
<td>2013年</td>
<td>图像生成、语音合成</td>
</tr>
<tr>
<td>2、生成对抗神经网络（GAN）</td>
<td>2014年</td>
<td>图像生成、语音合成</td>
</tr>
<tr>
<td>3、扩散模型（Diffusion Model）</td>
<td>2015年</td>
<td>图像生成</td>
</tr>
<tr>
<td>4、Transformer</td>
<td>2017年</td>
<td>语言模型</td>
</tr>
<tr>
<td>5、Vision Transformer（ViT）</td>
<td>2020年</td>
<td>视觉模型</td>
</tr>
</tbody></table>
<h6 id="2、预训练大模型"><a href="#2、预训练大模型" class="headerlink" title="2、预训练大模型"></a><strong>2、预训练大模型</strong></h6><p>虽然过去各种模型层出不穷，但是生成的内容偏简单且质量不高，远不能够满足现实场景中灵活多变以高质量内容生成的要求。<strong>预训练大模型</strong>的出现使 <strong>AIGC发生质变</strong> ，诸多问题得以解决。大模型在CV&#x2F;NLP&#x2F;多模态领域成果颇丰，并如下表的经典模型。诸如我们熟知的聊天对话模型ChatGPT，基于GPT-3.5大模型发展而来。</p>
<table>
<thead>
<tr>
<th>计算机视觉（CV）预训练大模型</th>
<th>自然语言处理（NLP）预训练大模型</th>
<th>多模态预训练大模型</th>
</tr>
</thead>
<tbody><tr>
<td>微软<strong>Florence</strong>（SwinTransformer）</td>
<td>谷歌Bert&#x2F;<strong>LaMDA</strong>&#x2F;PaLM</td>
<td>OpenAI的<strong>CLIP&#x2F;DALL-E</strong></td>
</tr>
<tr>
<td></td>
<td>OpenAI的GPT-3&#x2F;<strong>ChatGPT</strong></td>
<td>微软的GLIP</td>
</tr>
<tr>
<td></td>
<td></td>
<td>Stability AI的Stable Diffusion</td>
</tr>
</tbody></table>
<ul>
<li><strong>Florence</strong></li>
</ul>
<p>Florence是微软在2021年11月提出的视觉基础模型。Florence采用双塔Transformer结构。文本采用12层Transformer，视觉采用SwinTransformer。通过来自互联网的9亿图文对，采用Unified Contrasive Learning机制将图文映射到相同空间中。其可处理的下游任务包括：图文检索、图像分类、目标检测、视觉问答以及动作识别。</p>
<ul>
<li><strong>LaMDA</strong></li>
</ul>
<p>LaMDA是谷歌在2021年发布的大规模自然语言对话模型。LaMDA的训练过程分为预训练与微调两步。在预训练阶段，谷歌从公共数据数据中收集了1.56T数据集，feed给LaMDA，让其对自然语言有初步认识。</p>
<ul>
<li><strong>ChatGPT</strong></li>
</ul>
<p>ChatGPT是美国OpenAI公司在2022年11月发布的智能对话模型。截止目前ChatGPT未公开论文等技术资料。大多数的技术原理分析是基于InstructGPT分析。ChatGPT与GPT-3等对话模型不同的是，ChatGPT引入了人类反馈强化学习（HFRL：Human Feedback Reinforcement Learning）。</p>
<ul>
<li><strong>CLIP（OpenAI）</strong></li>
</ul>
<p>2021年美国OpenAI公司发布了跨模态预训练大模型CLIP，该模型采用从互联网收集的4亿对图文对。采用<strong>双塔模型</strong>与<strong>比对学习</strong>训练方式进行训练。CLIP的英文全称是Contrastive Language-Image Pre-training，即一种基于对比文本-图像对的预训练方法或者模型。</p>
<p>简单说，CLIP将图片与图片描述一起训练，达到的目的：给定一句文本，匹配到与文本内容相符的图片；给定一张图片，匹配到与图片相符的文本。</p>
<ul>
<li><strong>Stable Diffusion（Stablility AI）</strong></li>
</ul>
<p>Stable Diffusion是英国伦敦 Stability AI公司开源的图像生成扩散模型。Stable Diffusion的发布是AI图像生成发展过程中的一个里程碑，相当于给大众提供了一个可用的高性能模型，不仅生成的图像质量非常高，运行速度快，并且有资源和内存的要求也较低。</p>
<p>Omniverse，machinima、ZModeler绑定骨骼、建模 Character Creator（插件Headshot） 、Blender</p>
<h6 id="后续的"><a href="#后续的" class="headerlink" title="后续的"></a>后续的</h6><p><a target="_blank" rel="noopener" href="https://github.com/THUDM/ChatGLM-6B">THUDM&#x2F;ChatGLM-6B: ChatGLM-6B：开源双语对话语言模型 | An Open Bilingual Dialogue Language Model (github.com)</a></p>
<p><a target="_blank" rel="noopener" href="https://crfm.stanford.edu/2023/03/13/alpaca.html">斯坦福CRFM (stanford.edu)</a></p>
<p>Cerebras公司和开源gpt模型</p>
<p><a target="_blank" rel="noopener" href="https://www.cerebras.net/">主页 |脑 (cerebras.net)</a></p>
<p><a target="_blank" rel="noopener" href="https://huggingface.co/cerebras/Cerebras-GPT-13B">脑&#x2F;脑-GPT-13B ·拥抱脸 (huggingface.co)</a></p>
<!-- flag of hidden posts --></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://happywater520.github.io">小水</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://happywater520.github.io/2023/03/18/%E7%8B%AC%E7%AB%8B%E5%BC%80%E5%8F%91%E5%86%85%E5%AE%B9%E5%88%9B%E4%BD%9C/%E7%8B%AC%E7%AB%8B%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97/AIGC-%E7%A7%91%E6%8A%80%E8%B5%84%E8%AE%AF/">https://happywater520.github.io/2023/03/18/独立开发内容创作/独立开发指南/AIGC-科技资讯/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://happywater520.github.io" target="_blank">地球OL之小水篇</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="/../images/chatu/.png" data-sites="wechat,qq,weibo,facebook,twitter"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> 打赏</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/gongzhonghao.jpg" target="_blank"><img class="post-qr-code-img" src="/img/gongzhonghao.jpg" alt="关注就是对我的鼓励"/></a><div class="post-qr-code-desc">关注就是对我的鼓励</div></li></ul></div></div><nav class="pagination-post" id="pagination"></nav></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-6"><a class="toc-link" href="#%E4%B8%80%E4%BA%9B%E7%BD%91%E7%AB%99"><span class="toc-text">一些网站</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E4%B8%80%E4%BA%9B%E8%99%9A%E6%8B%9F%E5%BD%A2%E8%B1%A1%E7%9A%84%E7%94%9F%E6%88%90%E7%9A%84%E8%B5%84%E6%BA%90"><span class="toc-text">一些虚拟形象的生成的资源</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8Egpt%E7%9A%84%E5%B7%A5%E5%85%B7"><span class="toc-text">基于gpt的工具</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#GitHub-Copilot%E6%98%AF%E4%BB%80%E4%B9%88"><span class="toc-text">GitHub Copilot是什么</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E6%8E%A8%E7%90%86%E6%95%B0%E6%8D%AE%E9%9B%86%E6%98%AF%E4%BB%80%E4%B9%88"><span class="toc-text">自然语言推理数据集是什么</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#DALL%C2%B7E%E6%98%AF%E4%BB%80%E4%B9%88"><span class="toc-text">DALL·E是什么</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#OpenAI-API%E6%98%AF%E4%BB%80%E4%B9%88"><span class="toc-text">OpenAI API是什么</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E8%A7%84%E5%88%99%E7%9A%84%E5%A5%96%E5%8A%B1%E6%A8%A1%E5%9E%8B%EF%BC%88RBRMs%EF%BC%89%E6%98%AF%E4%BB%80%E4%B9%88"><span class="toc-text">基于规则的奖励模型（RBRMs）是什么</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#Microsoft-365-Copilot%E6%98%AF%E4%BB%80%E4%B9%88"><span class="toc-text">Microsoft 365 Copilot是什么</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E5%BF%83%E6%99%BA%E7%90%86%E8%AE%BA%EF%BC%88ToM%EF%BC%89%E6%98%AF%E4%BB%80%E4%B9%88"><span class="toc-text">心智理论（ToM）是什么</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#SkyNet%E6%98%AF%E4%BB%80%E4%B9%88"><span class="toc-text">SkyNet是什么</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#AI-1-0%E6%98%AF%E4%BB%80%E4%B9%88"><span class="toc-text">AI 1.0是什么</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E5%A4%9A%E6%A8%A1%E6%80%81%E6%98%AF%E4%BB%80%E4%B9%88"><span class="toc-text">多模态是什么</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#AIGC%E6%98%AF%E4%BB%80%E4%B9%88"><span class="toc-text">AIGC是什么</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#AIGC%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%BA%94%E7%94%A8%E5%85%A8%E8%A7%A3%E6%9E%90"><span class="toc-text">AIGC技术与应用全解析</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#1%E3%80%81%E5%9F%BA%E7%A1%80%E6%A8%A1%E5%9E%8B"><span class="toc-text">1、基础模型</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#2%E3%80%81%E9%A2%84%E8%AE%AD%E7%BB%83%E5%A4%A7%E6%A8%A1%E5%9E%8B"><span class="toc-text">2、预训练大模型</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E5%90%8E%E7%BB%AD%E7%9A%84"><span class="toc-text">后续的</span></a></li></ol></div></div></div></div></main><footer id="footer" style="background-image: url('/../images/chatu/.png')"><div id="footer-wrap"><div class="copyright">&copy;2016 - 2023 By 小水</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text"><a target="_blank" rel="noopener" href="http://beian.miit.gov.cn"><img class="icp-icon" src="icp图片"><span>备案号：桂ICP备2023005211号</span></a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>(() => {
  const $mermaid = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaid.length === 0) return
  const runMermaid = () => {
    window.loadMermaid = true
    const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

    Array.from($mermaid).forEach((item, index) => {
      const mermaidSrc = item.firstElementChild
      const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
      const mermaidID = 'mermaid-' + index
      const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent

      const renderFn = mermaid.render(mermaidID, mermaidDefinition)

      const renderV10 = () => {
        renderFn.then(({svg}) => {
          mermaidSrc.insertAdjacentHTML('afterend', svg)
        })
      }

      const renderV9 = svg => {
        mermaidSrc.insertAdjacentHTML('afterend', svg)
      }

      typeof renderFn === 'string' ? renderV9(renderFn) : renderV10()
    })
  }

  const loadMermaid = () => {
    window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaid)
  }

  btf.addModeChange('mermaid', runMermaid)

  window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
})()</script><script>(() => {
  function abcjsInit() {
    function abcjsFn() {
      for (let abcContainer of document.getElementsByClassName("abc-music-sheet")) {
        ABCJS.renderAbc(abcContainer, abcContainer.innerHTML, {responsive: 'resize'})
      }
    }
    
    typeof ABCJS === 'object' ? abcjsFn()
      : getScript('https://cdn.jsdelivr.net/npm/abcjs/dist/abcjs-basic-min.min.js').then(abcjsFn)
  }

  window.pjax ? abcjsInit() : document.addEventListener('DOMContentLoaded', abcjsInit)
})()</script></div><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script id="click-show-text" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-show-text.min.js" data-mobile="false" data-text="❤,❤,喜,欢,你,❤,❤,❤" data-fontsize="15px" data-random="false" async="async"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>